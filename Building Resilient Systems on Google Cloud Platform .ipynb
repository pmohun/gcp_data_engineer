{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenges associated with streaming data\n",
    "\n",
    "#### Ingesting variable volumes\n",
    "- massive amounts of streaming events, handle spiky/bursting data, high availability and durability\n",
    "- Cloud Pub/Sub (Ingest)\n",
    "\n",
    "#### Late data, unordered data\n",
    "- how to deal with latency, late arriving records, or speculative results\n",
    "- Data Dataflow (Processing & Imperative Analysis)\n",
    "\n",
    "#### Real-time insights\n",
    "- continuous query processing, visualization, analytics, etc.\n",
    "- Google BigQuery (Durable storage and interactive analysis)\n",
    "\n",
    "## Module 1 Review\n",
    "\n",
    "1.) Dataflow offers the following that makes it easy to create resilient streaming pipelines when working with unbounded data\n",
    "- Ability to flexibly reason about time\n",
    "- Control messages to ensure correctness\n",
    "\n",
    "2.) Match the GCP product with its role when designing streaming systems\n",
    "- Pub / Sub: Global messaging queue\n",
    "- Dataflow: Controls to handle late-arriving and out-of-order data\n",
    "- Bigtable: latency in the order of milliseconds when querying against overwhelming volume\n",
    "- BiqQuery: Query data as it arrives from streaming pipelines\n",
    "\n",
    "## Lab: Publish Streaming Data into Pub/Sub\n",
    "#### Objectives:\n",
    "- Create a Pub/Sub topic and subscription\n",
    "- Simulate your traffic sensor data into Pub/Sub\n",
    "\n",
    "#### Task 1: Preparation\n",
    "- In the Console, on the Navigation menu () click Compute Engine > VM instances.\n",
    "- Locate the line with the instance called training_vm.\n",
    "- On the far right, under 'connect', Click on SSH to open a terminal window.\n",
    "- In this lab you will enter CLI commands on the training_vm.\n",
    "- The training_vm is installing software in the background. Verify that setup is complete by checking that the following directory exists. If it does not exist, wait a few minutes and try again\n",
    "- A repository has been downloaded to the VM. Copy the repository to your home directory.\n",
    "\n",
    "```\n",
    "ls /training\n",
    "# copy to home directory\n",
    "cp -r /training/training-data-analyst/ .\n",
    "```\n",
    "- On the training_vm SSH terminal, set the DEVSHELL_PROJECT_ID environment variable and export it so it will be available to other shells.\n",
    "```\n",
    "export DEVSHELL_PROJECT_ID=<project-id>\n",
    "```\n",
    "\n",
    "#### Task 2: Create Pub/Sub topic and subscription\n",
    "- On the training_vm SSH terminal, navigate to the directory for this lab.\n",
    "```\n",
    "cd ~/training-data-analyst/courses/streaming/publish\n",
    "gcloud pubsub topics create sandiego\n",
    "gcloud pubsub topics publish sandiego --message \"hello\"\n",
    "gcloud pubsub subscriptions create --topic sandiego mySub1\n",
    "gcloud pubsub subscriptions pull --auto-ack mySub1\n",
    "# try again\n",
    "gcloud pubsub topics publish sandiego --message \"hello again\"\n",
    "gcloud pubsub subscriptions pull --auto-ack mySub1\n",
    "```\n",
    "\n",
    "- Return to the Console tab. On the Navigation menu () click Pub/Sub > Topics.\n",
    "- You should see a line with the Topic Name ending in sandiego and the number of Subscriptions set to 1.\n",
    "- In the training_vm SSH terminal,, cancel your subscription.\n",
    "\n",
    "```\n",
    "gcloud pubsub subscriptions delete mySub1\n",
    "```\n",
    "\n",
    "#### Task 3: Simulate traffic sensor data into Pub/Sub\n",
    "- Explore the python script to simulate San Diego traffic sensor data. Do not make any changes to the code.\n",
    "```\n",
    "cd ~/training-data-analyst/courses/streaming/publish\n",
    "nano send_sensor_data.py\n",
    "```\n",
    "- Download the traffic simulation dataset.\n",
    "```\n",
    "./download_data.sh\n",
    "sudo apt-get install -y python-pip\n",
    "sudo pip install -U google-cloud-pubsub\n",
    "./send_sensor_data.py --speedFactor=60 --project (dollar sign)DEVSHELL_PROJECT_ID\n",
    "```\n",
    "\n",
    "- This command simulates sensor data by sending recorded sensor data via Pub/Sub messages. The script extracts the original time of the sensor data and pauses between sending each message to simulate realistic timing of the sensor data. The value speedFactor changes the time between messages proportionally. So a speedFactor of 60 means '60 times faster' than the recorded timing. It will send about an hour of data every 60 seconds.\n",
    "\n",
    "#### Task 4: Verify that messages are received\n",
    "- In the Console, on the Navigation menu () click Compute Engine > VM instances.\n",
    "- Locate the line with the instance called training_vm.\n",
    "- On the far right, under 'connect', Click on SSH to open a second terminal window.\n",
    "- Change into the directory you were working in:\n",
    "```\n",
    "cd ~/training-data-analyst/courses/streaming/publish\n",
    "gcloud pubsub subscriptions create --topic sandiego mySub2\n",
    "gcloud pubsub subscriptions pull --auto-ack mySub2\n",
    "# cancel subscription\n",
    "gcloud pubsub subscriptions delete mySub2\n",
    "exit\n",
    "```\n",
    "\n",
    "## End Lab\n",
    "\n",
    "## Module 2 Review\n",
    "\n",
    "1.) Which of the following about Cloud Pub/Sub is NOT true?\n",
    "- Pub/Sub stores your messages indefinitely until you need it\n",
    "\n",
    "Pub/Sub does:\n",
    "- Simplify systems by removing the need for every component to speak to every component\n",
    "- Connect applications and devices through a messaging infrastructure\n",
    "\n",
    "2.) Cloud Pub/Sub guarantees that messages delivered are in the order they were received\n",
    "- False\n",
    "(Pub/Sub takes advantage of timestamping to deliver in the correct order)\n",
    "\n",
    "3.) Which of the following about Cloud Pub/Sub topics and subscriptions are true?\n",
    "- 1 or more publishers can write to the same topic\n",
    "- 1 or more subscribers can request from the same subscription\n",
    "\n",
    "4.) Which of the following delivery methods is ideal for subscribers needing close to real time performance?\n",
    "- Push delivery \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
